---
layout: post
title: NAACL papers I'm excited for
---

<div class="message">
    Based on their titles alone...
</div>

I just found out my company is sending me to NAACL! Thank you, Networked Insights 😁.
The [list of accepted NAACL papers](https://naacl2018.wordpress.com/2018/03/02/list-of-accepted-papers/) came out about a month ago and more and more papers are showing up on arXiv every day.

Here are 10 interesting-sounding papers and what I could find out about them.


## A corpus of non-native written English annotated for metaphor
_Beata Beigman Klebanov, Chee Wee (Ben) Leong and Michael Flor_

Interesting to note that Beata Beigman Klemanov (what an iconic name by the way) works at ETS. It makes sense to me that the people who make those tests would be into this kind of annotation. It's also cool that it's non-native English  because you don't see a lot of datasets that are explicitly that and I don't know what percentage of English speakers are non-native but I'm sure it's a ***lot***\*. 

\* Holy #\*@%! L2 English speakers outnumber L1 speakers by a ration of 3 to 1! 


## Dear Sir or Madam, May I introduce the YAFC corpus: Corpus, benchmarks and metrics for formality style transfer
_Sudha Rao and Joel Tetreault_

[Joel Tetreault](https://twitter.com/tetreault_nlp) works at [Grammerly](https://en.wikipedia.org/wiki/Grammarly) which makes software that does what they call _writing enhancement_ which surely includes spelling and grammar, but perhaps also some tooling around formality?. 

[Sudha Rao](https://raosudha.weebly.com/) is an early PhD at UMD advised by Hal Daumé which makes me incredibly jealuous.
She also interned at Grammarly last summer which is surely where this work comes from. Also, her [thesis project](https://www.scribd.com/document/351169976/Teaching-Machines-to-Ask-Clarification-Questions) includes grounding which is a [favorite topic of mine](https://en.wikipedia.org/wiki/Grounding_in_communication). 

## ATTR2VEC: Jointly learning word and contextual attribute embeddings with factorization machines
_Fabio Petroni, Vassilis Plachouras, Timothy Nugent and Jochen L. Leidner_

I'm always interested in work that tries to capture contextual information, especially when it's giving structure to word embeddings, which it sounds like this might. The authors have released their code on [github](https://github.com/thomsonreuters/attr2vec) but the readme is all business and I don't know enough about the topic to tell from the code what is going on, so I'll wait.

## Deep contextualized word representations
_Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee and Luke Zettlemoyer_

I was a little skeptical of this work at first, I mean [hasn't](https://arxiv.org/pdf/1502.07257.pdf) this [been](http://www.aclweb.org/anthology/W16-5307) done [already](https://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors.pdf)? But I'm not sure any of those embeddings proved to be so useful for a broad variety of tasks, as this approach claims to. Also they've put both [code](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md) up in both TensorFlow and PyTorch with tutorials and everything. Way to go AllenNLP 😊

## Diachronic usage relatedness (DUREL): A framework for the annotation of lexical semantic change
_Dominik Schlechtweg, Sabine Schulte im Walde and Stefanie Eckmann_

These folks take a different approach from the diachronic semantics papers I wrote about [a few weeks ago]({% post_url 2018-04-28-naacl-2018 %}). Instead of comparing embeddings, they compare usage directly. How do they do that? They take a bunch instances of a word being used in context from one time period and pair them up with usages from another time period and then look at averages across different measures of comparison between the two usages. 

The authors come up with two different measures, and claim one of them can tell the difference between _innovative_ and _reductive_ semantic change.

## Attentive interaction model: Modeling changes in view in argumentation
_Yohan Jo, Shivani Poddar, Byungsoo Jeon, Qinlan Shen, Carolyn Rose and Graham Neubig_

When I read this title I knew immediately that they used [/r/changemyview](https://reddit.com/r/changemyview). An [earlier paper](https://arxiv.org/abs/1602.01103) by some of the Cornell computational sociolinguistics folks comes with a really nice dataset for it (with annotations)! They are so good about releasing data that's well documented, easy to use and not 404'd. [(arXiv)](https://arxiv.org/abs/1804.00065)

## Author commitment and social power: Automatic belief tagging to infer the social context of interactions
_Vinodkumar Prabhakaran and Owen Rambow_

I took a look at the [author's thesis](http://www.cs.columbia.edu/nlp/theses/vinodkumar_prabhakaran.pdf). One of the main ideas is that you can predict social power based on their _level of belief_ in their utterances. "i.e., whether the participants are committed to the beliefs they express, non-committed to them, or express beliefs attributed to someone else". Sounds pretty interesting and I think that's what this paper is going to be about.

## Deconfounded lexicon induction for interpretable social science
_Reid Pryzant, Kelly Shen, Dan Jurafsky and Stefan Wagner_

I'm very interested in this enigmatically titled paper. What is this lexicon and what does it mean for it to be _deconfounded_? In what way is it being _induced_? And we're doing... what with it? Interpreting social science!?! Fascinating. Unfortunately, all I could find is this [broken link](https://nlp.stanford.edu/projects/deconfounded-lexicon-induction/). 
 
There is also this [Github project](https://github.com/rpryzant/deconfounded_lexicon_induction) but but my mother told me to poke around in a code repository I know nothing about.

## Colorless green recurrent networks dream hierarchically
_Kristina Gulordava, Marco Baroni, Tal Linzen, Piotr Bojanowski and Edouard Grave_

Dad joke level title, but atually pretty descriptive. The authors want to see if RNNs learn abstract hierarchical syntactic structure. In other words, do they understand the ways in which words build into phrases and phrases build into sentences, and how they're connected once they do? 
> 
> To test this, they test if the RNN language model can get syntactic number agreement right in meaningless (but syntactically correct) sentences like "The colorless greed **ideas** I ate with the chair **sleep** furiously". In this example, if the RNN predicts _sleep_, which agrees with _ideas_ rather than _sleeps_, then that's evidence the RNN understands the syntactic structure.

## Deep dungeons and dragons: Learning character-action interactions from role-playing game transcripts
_Annie Louis and Charles Sutton_

Well this is clearly awesome. I'm not sure exactly what it means for a character to interact with an action, but I'm excited to find out. Couldn't find so much as an abstract online, and the authors' past work doesn't have any big hints so we'll have to wait to find out.

